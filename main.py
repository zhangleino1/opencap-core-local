"""
    @authors: Scott Uhlrich, Antoine Falisse, Åukasz KidziÅ„ski
    
    This function calibrates the cameras, runs the pose detection algorithm, 
    reconstructs the 3D marker positions, augments the marker set,
    and runs the OpenSim pipeline.

"""

import os 
import glob
import numpy as np
import yaml
import json
import traceback

import logging
logging.basicConfig(level=logging.INFO)

from utils import importMetadata, loadCameraParameters, getVideoExtension
from utils import getDataDirectory, getOpenPoseDirectory, getMMposeDirectory
from utilsChecker import saveCameraParameters
from utilsChecker import calcExtrinsicsFromVideo
from utilsChecker import isCheckerboardUpsideDown
from utilsChecker import autoSelectExtrinsicSolution
from utilsChecker import synchronizeVideos
from utilsChecker import triangulateMultiviewVideo
from utilsChecker import writeTRCfrom3DKeypoints
from utilsChecker import popNeutralPoseImages
from utilsChecker import rotateIntrinsics
from utilsDetector  import runPoseDetector
from utilsAugmenter import augmentTRC
from utilsOpenSim import runScaleTool, getScaleTimeRange, runIKTool, generateVisualizerJson

def main(sessionName, trialName, trial_id, cameras_to_use=['all'],
         intrinsicsFinalFolder='Deployed', isDocker=False,
         extrinsicsTrial=False, alternateExtrinsics=None, 
         calibrationOptions=None,
         markerDataFolderNameSuffix=None, imageUpsampleFactor=4,
         poseDetector='OpenPose', resolutionPoseDetection='default', 
         scaleModel=False, bbox_thr=0.8, augmenter_model='v0.3',
         genericFolderNames=False, offset=True, benchmark=False,
         dataDir=None, overwriteAugmenterModel=False,
         filter_frequency='default', overwriteFilterFrequency=False,
         scaling_setup='upright_standing_pose', overwriteScalingSetup=False,
         overwriteCamerasToUse=False):

    # %% High-level settings.
    # Camera calibration.
    runCameraCalibration = True
    # Pose detection.
    runPoseDetection = True
    # Video Synchronization.
    runSynchronization = True
    # Triangulation.
    runTriangulation = True
    # Marker augmentation.
    runMarkerAugmentation = True
    # OpenSim pipeline.
    runOpenSimPipeline = True    
    # High-resolution for OpenPose.
    resolutionPoseDetection = resolutionPoseDetection
    # Set to False to only generate the json files (default is True).
    # This speeds things up and saves storage space.
    generateVideo = True
    # This is a hack to handle a mismatch between the use of mmpose and hrnet,
    # and between the use of OpenPose and openpose.
    if poseDetector == 'hrnet':
        poseDetector = 'mmpose'        
    elif poseDetector == 'openpose':
        poseDetector = 'OpenPose'
    if poseDetector == 'mmpose':
        outputMediaFolder = 'OutputMedia_mmpose' + str(bbox_thr)
    elif poseDetector == 'OpenPose':
        outputMediaFolder = 'OutputMedia_' + resolutionPoseDetection
    
    # %% Special case: extrinsics trial.
    # For that trial, we only calibrate the cameras.
    if extrinsicsTrial:
        runCameraCalibration = True
        runPoseDetection = False
        runSynchronization = False
        runTriangulation =  False
        runMarkerAugmentation = False
        runOpenSimPipeline = False
        
    # %% Paths and metadata. This gets defined through web app.
    baseDir = os.path.dirname(os.path.abspath(__file__))
    if dataDir is None:
        dataDir = getDataDirectory(isDocker)
    if 'dataDir' not in locals():
        sessionDir = os.path.join(baseDir, 'Data', sessionName)
    else:
        sessionDir = os.path.join(dataDir, 'Data', sessionName)
    sessionMetadata = importMetadata(os.path.join(sessionDir,
                                                  'sessionMetadata.yaml'))
    
    # If augmenter model defined through web app.
    # If overwriteAugmenterModel is True, the augmenter model is the one
    # passed as an argument to main(). This is useful for local testing.
    if 'augmentermodel' in sessionMetadata and not overwriteAugmenterModel:
        augmenterModel = sessionMetadata['augmentermodel']
    else:
        augmenterModel = augmenter_model
        
    # Lowpass filter frequency of 2D keypoints for gait and everything else.
    # If overwriteFilterFrequency is True, the filter frequency is the one
    # passed as an argument to main(). This is useful for local testing.
    if 'filterfrequency' in sessionMetadata and not overwriteFilterFrequency:
        filterfrequency = sessionMetadata['filterfrequency']
    else:
        filterfrequency = filter_frequency
    if filterfrequency == 'default':
        filtFreqs = {'gait':12, 'default':500} # defaults to framerate/2
    else:
        filtFreqs = {'gait':filterfrequency, 'default':filterfrequency}

    # If scaling setup defined through web app.
    # If overwriteScalingSetup is True, the scaling setup is the one
    # passed as an argument to main(). This is useful for local testing.
    if 'scalingsetup' in sessionMetadata and not overwriteScalingSetup:
        scalingSetup = sessionMetadata['scalingsetup']
    else:
        scalingSetup = scaling_setup

    # If camerastouse is in sessionMetadata, reprocess with specified cameras.
    # This allows reprocessing trials with missing videos. If
    # overwriteCamerasToUse is True, the camera selection is the one
    # passed as an argument to main(). This is useful for local testing.
    if 'camerastouse' in sessionMetadata and not overwriteCamerasToUse:
        camerasToUse = sessionMetadata['camerastouse']
    else:
        camerasToUse = cameras_to_use

    # %% Paths to pose detector folder for local testing.
    if poseDetector == 'OpenPose':
        poseDetectorDirectory = getOpenPoseDirectory(isDocker)
    elif poseDetector == 'mmpose':
        poseDetectorDirectory = getMMposeDirectory(isDocker)    
        
    # %% Create marker folders
    # Create output folder.
    if genericFolderNames:
        markerDataFolderName = os.path.join('MarkerData') 
    else:
        if poseDetector == 'mmpose':
            suff_pd = '_' + str(bbox_thr)
        elif poseDetector == 'OpenPose':
            suff_pd = '_' + resolutionPoseDetection
                
        markerDataFolderName = os.path.join('MarkerData', 
                                            poseDetector + suff_pd) 
        if not markerDataFolderNameSuffix is None:
            markerDataFolderName = os.path.join(markerDataFolderName,
                                                markerDataFolderNameSuffix)
    preAugmentationDir = os.path.join(sessionDir, markerDataFolderName,
                                      'PreAugmentation')
    os.makedirs(preAugmentationDir, exist_ok=True)
    
    # Create augmented marker folders as well
    if genericFolderNames:
        postAugmentationDir = os.path.join(sessionDir, markerDataFolderName, 
                                           'PostAugmentation')
    else:
        postAugmentationDir = os.path.join(
            sessionDir, markerDataFolderName, 
            'PostAugmentation_{}'.format(augmenterModel))
    os.makedirs(postAugmentationDir, exist_ok=True)
        
    # %% Dump settings in yaml.
    if not extrinsicsTrial:
        pathSettings = os.path.join(postAugmentationDir,
                                    'Settings_' + trial_id + '.yaml')
        settings = {
            'poseDetector': poseDetector, 
            'augmenter_model': augmenterModel, 
            'imageUpsampleFactor': imageUpsampleFactor,
            'openSimModel': sessionMetadata['openSimModel'],
            'scalingSetup': scalingSetup,
            'filterFrequency': filterfrequency,
            }
        if poseDetector == 'OpenPose':
            settings['resolutionPoseDetection'] = resolutionPoseDetection
        elif poseDetector == 'mmpose':
            settings['bbox_thr'] = bbox_thr
        with open(pathSettings, 'w', encoding='utf-8') as file:
            yaml.dump(settings, file)

    # %% Camera calibration.
    if runCameraCalibration:    
        # Get checkerboard parameters from metadata.
        CheckerBoardParams = {
            'dimensions': (
                sessionMetadata['checkerBoard']['black2BlackCornersWidth_n'],
                sessionMetadata['checkerBoard']['black2BlackCornersHeight_n']),
            'squareSize': 
                sessionMetadata['checkerBoard']['squareSideLength_mm']}       
        # Camera directories and models.
        cameraDirectories = {}
        cameraModels = {}
        for pathCam in glob.glob(os.path.join(sessionDir, 'Videos', 'Cam*')):
            if os.name == 'nt': # windows
                camName = pathCam.split('\\')[-1]
            elif os.name == 'posix': # ubuntu
                camName = pathCam.split('/')[-1]
            cameraDirectories[camName] = os.path.join(sessionDir, 'Videos',
                                                      pathCam)
            # æ”¯æŒé€šç”¨æ‘„åƒå¤´ï¼Œä¸ä»…ä»…æ˜¯iPhone
            if 'cameraModel' in sessionMetadata:
                cameraModels[camName] = sessionMetadata['cameraModel'][camName]
            elif 'iphoneModel' in sessionMetadata:
                # å‘åå…¼å®¹æ—§çš„å­—æ®µå
                cameraModels[camName] = sessionMetadata['iphoneModel'][camName]
            else:
                # å¦‚æœæ²¡æœ‰æ‘„åƒå¤´å‹å·ä¿¡æ¯ï¼Œä½¿ç”¨é€šç”¨å‘½å
                cameraModels[camName] = f'GenericCamera_{camName}'        
        
        # Get cameras' intrinsics and extrinsics.     
        # Load parameters if saved, compute and save them if not.
        CamParamDict = {}
        loadedCamParams = {}
        for camName in cameraDirectories:
            camDir = cameraDirectories[camName]
            # Intrinsics ######################################################
            # Intrinsics and extrinsics already exist for this session.
            if os.path.exists(
                    os.path.join(camDir,"cameraIntrinsicsExtrinsics.pickle")):
                logging.info("Load extrinsics for {} - already existing".format(
                    camName))
                CamParams = loadCameraParameters(
                    os.path.join(camDir, "cameraIntrinsicsExtrinsics.pickle"))
                loadedCamParams[camName] = True
                
            # Extrinsics do not exist for this session.
            else:
                logging.info("Compute extrinsics for {} - not yet existing".format(camName))
                # Intrinsics ##################################################
                # Intrinsics directories.
                intrinsicDir = os.path.join(baseDir, 'CameraIntrinsics',
                                            cameraModels[camName])
                permIntrinsicDir = os.path.join(intrinsicDir, 
                                                intrinsicsFinalFolder)            
                # Intrinsics exist.
                if os.path.exists(permIntrinsicDir):
                    CamParams = loadCameraParameters(
                        os.path.join(permIntrinsicDir,
                                      'cameraIntrinsics.pickle'))                    
                # Intrinsics do not exist throw an error. Eventually the
                # webapp will give you the opportunity to compute them.
                
                else:
                    # å¯¹äºæœ¬åœ°å¤„ç†ï¼Œå¦‚æœæ˜¯é€šç”¨æ‘„åƒå¤´ä¸”æ²¡æœ‰é¢„è®¡ç®—çš„å†…å‚ï¼Œ
                    # å°è¯•ä»å½“å‰æ ‡å®šè§†é¢‘è®¡ç®—å†…å‚
                    if 'GenericCamera' in cameraModels[camName] and extrinsicsTrial:
                        logging.info(f"ä¸ºé€šç”¨æ‘„åƒå¤´ {camName} è®¡ç®—å†…å‚...")
                        try:
                            # å¯¼å…¥æœ¬åœ°å†…å‚è®¡ç®—å‡½æ•°
                            from main_calcIntrinsics_local import calibrateCameraFromVideo
                            
                            # ä»å½“å‰æ ‡å®šè§†é¢‘è®¡ç®—å†…å‚
                            pathVideoWithoutExtension = os.path.join(
                                camDir, 'InputMedia', trialName, trial_id)
                            extension = getVideoExtension(pathVideoWithoutExtension)
                            calibrationVideoPath = pathVideoWithoutExtension + extension
                            
                            if os.path.exists(calibrationVideoPath):
                                # ä½¿ç”¨é»˜è®¤å›¾åƒæ•°é‡25è¿›è¡Œæ ‡å®š
                                intrinsic_data = calibrateCameraFromVideo(
                                    calibrationVideoPath, CheckerBoardParams, 25)
                                if intrinsic_data is None:
                                    raise Exception(f"ä»è§†é¢‘è®¡ç®—å†…å‚å¤±è´¥: {calibrationVideoPath}")
                                
                                # åˆ›å»ºå…¼å®¹çš„å†…å‚å­—å…¸æ ¼å¼ï¼ˆä¸ç°æœ‰å‡½æ•°å…¼å®¹ï¼‰
                                CamParams = {
                                    'intrinsicMat': intrinsic_data['intrinsicMat'],
                                    'distortion': intrinsic_data['distortion'],
                                    'imageSize': intrinsic_data['imageSize']
                                }
                                logging.info(f"æˆåŠŸä¸º {camName} è®¡ç®—å†…å‚")
                            else:
                                raise Exception(f"æ ‡å®šè§†é¢‘ä¸å­˜åœ¨: {calibrationVideoPath}")
                                
                        except ImportError:
                            exception = "æ— æ³•å¯¼å…¥æœ¬åœ°å†…å‚è®¡ç®—æ¨¡å—ã€‚è¯·ç¡®ä¿ main_calcIntrinsics_local.py å­˜åœ¨ã€‚"
                            raise Exception(exception, exception)
                        except Exception as e:
                            exception = f"ä¸ºé€šç”¨æ‘„åƒå¤´è®¡ç®—å†…å‚å¤±è´¥: {str(e)}"
                            raise Exception(exception, exception)
                    else:
                        # å¯¹äºéæ ‡å®šè¯•éªŒï¼Œå¦‚æœæ˜¯é€šç”¨æ‘„åƒå¤´ä¸”æ²¡æœ‰å†…å‚ï¼Œæä¾›æ›´æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
                        if 'GenericCamera' in cameraModels[camName]:
                            exception = f"é€šç”¨æ‘„åƒå¤´ {camName} ç¼ºå°‘å†…å‚æ•°æ®ã€‚è¯·å…ˆè¿è¡Œæ ‡å®šè¯•éªŒä»¥è®¡ç®—å†…å‚ï¼Œæˆ–æ‰‹åŠ¨æä¾›å†…å‚æ–‡ä»¶ã€‚"
                            raise Exception(exception, exception)
                        else:
                            exception = "Intrinsics don't exist for your camera model. OpenCap supports all iOS devices released in 2018 or later: https://www.opencap.ai/get-started."
                            raise Exception(exception, exception)
                        
                # Extrinsics ##################################################
                # Compute extrinsics from images popped out of this trial.
                # Hopefully you get a clean shot of the checkerboard in at
                # least one frame of each camera.
                useSecondExtrinsicsSolution = (
                    alternateExtrinsics is not None and
                    camName in alternateExtrinsics)
                logging.info(f"   ğŸ¯ {camName} å¤–å‚è®¡ç®—è®¾ç½®:")
                logging.info(f"      ä½¿ç”¨å¤‡é€‰è§£å†³æ–¹æ¡ˆ: {useSecondExtrinsicsSolution}")

                pathVideoWithoutExtension = os.path.join(
                    camDir, 'InputMedia', trialName, trial_id)
                extension = getVideoExtension(pathVideoWithoutExtension)
                extrinsicPath = os.path.join(camDir, 'InputMedia', trialName,
                                             trial_id + extension)
                logging.info(f"      æ ‡å®šè§†é¢‘è·¯å¾„: {extrinsicPath}")

                # Modify intrinsics if camera view is rotated
                logging.info(f"      å›¾åƒä¸Šé‡‡æ ·å› å­: {imageUpsampleFactor}")
                CamParams = rotateIntrinsics(CamParams,extrinsicPath)

                # for 720p, imageUpsampleFactor=4 is best for small board
                try:
                    CamParams = calcExtrinsicsFromVideo(
                        extrinsicPath,CamParams, CheckerBoardParams,
                        visualize=False, imageUpsampleFactor=imageUpsampleFactor,
                        useSecondExtrinsicsSolution = useSecondExtrinsicsSolution)

                    # è®°å½•å¤–å‚è®¡ç®—ç»“æœ
                    if 'rotation' in CamParams:
                        import numpy as np  # ç¡®ä¿numpyåœ¨æœ¬åœ°ä½œç”¨åŸŸå†…å¯ç”¨
                        rotation = CamParams['rotation']
                        translation = CamParams['translation']
                        logging.info(f"   âœ… {camName} å¤–å‚è®¡ç®—æˆåŠŸ:")
                        logging.info(f"      æ—‹è½¬çŸ©é˜µè¡Œåˆ—å¼: {np.linalg.det(rotation):.6f} (åº”è¯¥æ¥è¿‘1)")
                        logging.info(f"      å¹³ç§»å‘é‡æ¨¡é•¿: {np.linalg.norm(translation):.3f} mm")
                        logging.info(f"      ç›¸æœºä½ç½®: [{translation[0][0]:.1f}, {translation[1][0]:.1f}, {translation[2][0]:.1f}] mm")

                except Exception as e:
                    if len(e.args) == 2: # specific exception
                        raise Exception(e.args[0], e.args[1])
                    elif len(e.args) == 1: # generic exception
                        exception = "Camera calibration failed. Verify your setup and try again. Visit https://www.opencap.ai/best-pratices to learn more about camera calibration and https://www.opencap.ai/troubleshooting for potential causes for a failed calibration."
                        raise Exception(exception, traceback.format_exc())
                loadedCamParams[camName] = False
                
       
            # Append camera parameters.
            if CamParams is not None:
                CamParamDict[camName] = CamParams.copy()
            else:
                CamParamDict[camName] = None

        # Save parameters if not existing yet.
        if not all([loadedCamParams[i] for i in loadedCamParams]):
            for camName in CamParamDict:
                saveCameraParameters(
                    os.path.join(cameraDirectories[camName],
                                 "cameraIntrinsicsExtrinsics.pickle"), 
                    CamParamDict[camName])
            
    # %% 3D reconstruction
    
    # Set output file name.
    pathOutputFiles = {}
    if benchmark:
        pathOutputFiles[trialName] = os.path.join(preAugmentationDir,
                                                  trialName + ".trc")
    else:
        pathOutputFiles[trialName] = os.path.join(preAugmentationDir,
                                                  trial_id + ".trc")
    
    # Trial relative path
    trialRelativePath = os.path.join('InputMedia', trialName, trial_id)
    
    if runPoseDetection:
        # Get rotation angles from motion capture environment to OpenSim.
        # Space-fixed are lowercase, Body-fixed are uppercase.
        checkerBoardMount = sessionMetadata['checkerBoard']['placement']
        logging.info(f"ğŸ¯ æ£‹ç›˜æ ¼æ”¾ç½®æ–¹å¼: {checkerBoardMount}")
        logging.info("=" * 80)
        logging.info("ğŸ”„ å¼€å§‹åæ ‡ç³»è½¬æ¢é…ç½®åˆ†æ")
        logging.info("=" * 80)

        if checkerBoardMount == 'backWall' or checkerBoardMount == 'Perpendicular':
            # æ”¹è¿›çš„æ£‹ç›˜æ ¼å€’ç½®æ£€æµ‹
            logging.info("ğŸ” èƒŒå¢™æ”¾ç½®æ¨¡å¼ï¼Œå¼€å§‹æ£€æµ‹æ£‹ç›˜æ ¼æœå‘...")
            logging.info("   ğŸ“‹ èƒŒå¢™æ¨¡å¼è¯´æ˜:")
            logging.info("      - æ£‹ç›˜æ ¼å‚ç›´æ”¾ç½®åœ¨å¢™ä¸Š")
            logging.info("      - éœ€è¦æ£€æµ‹æ£‹ç›˜æ ¼æ˜¯å¦å€’ç½®")
            logging.info("      - æ ¹æ®æ£€æµ‹ç»“æœé€‰æ‹©ä¸åŒçš„åæ ‡ç³»è½¬æ¢")

            # è®°å½•æ‘„åƒå¤´å‚æ•°ç”¨äºè°ƒè¯•
            logging.info(f"   ğŸ“· å¯ç”¨æ‘„åƒå¤´æ•°é‡: {len(CamParamDict)}")
            for cam_name in CamParamDict.keys():
                logging.info(f"      - {cam_name}: å¤–å‚å·²åŠ è½½")



            upsideDownChecker = isCheckerboardUpsideDown(CamParamDict)
            logging.info(f"   ğŸ§­ æ£‹ç›˜æ ¼å€’ç½®æ£€æµ‹ç»“æœ: {upsideDownChecker}")


            if upsideDownChecker:
                rotationAngles = {'y':-90}
                logging.info("ğŸ”„ æ£€æµ‹åˆ°æ£‹ç›˜æ ¼å€’ç½®ï¼Œåº”ç”¨å€’ç½®è¡¥å¿æ—‹è½¬:")
                logging.info("   yè½´æ—‹è½¬: -90Â°")
                logging.info("   ğŸ“ è¯´æ˜: opencv yè½´å‚ç›´å‘ä¸Š,xè½´è¶…å·¦,zè½´è¶…å¤– è½¬å‘ xè½´è¶…å‰ï¼Œzè¶…å·¦å’ŒOpensim åæ ‡è½´è¦æ±‚å¯¹é½")
            else:
                rotationAngles = {'y':90, 'z':180}
                logging.info("ğŸ”„ æ£€æµ‹åˆ°æ£‹ç›˜æ ¼æ­£å‘ï¼Œåº”ç”¨æ ‡å‡†èƒŒå¢™æ—‹è½¬:")
                logging.info("   Yè½´æ—‹è½¬: +90Â°")
                logging.info("   Zè½´æ—‹è½¬: +180Â°")
                logging.info("   ğŸ“ è¯´æ˜: ä»èƒŒå¢™åæ ‡ç³»è½¬æ¢åˆ°OpenSimåæ ‡ç³»")

        elif checkerBoardMount == 'ground' or checkerBoardMount == 'Lying':
            rotationAngles = {'x':90, 'y':90}
            logging.info("ğŸ”„ åœ°é¢æ”¾ç½®æ¨¡å¼ï¼Œåº”ç”¨åœ°é¢æ—‹è½¬:")
            logging.info("   Xè½´æ—‹è½¬: +90Â°")
            logging.info("   Yè½´æ—‹è½¬: +90Â°")
            logging.info("   ğŸ“ è¯´æ˜: ä»åœ°é¢åæ ‡ç³»è½¬æ¢åˆ°OpenSimåæ ‡ç³»")
        else:
            error_msg = f'æ£‹ç›˜æ ¼æ”¾ç½®æ–¹å¼ "{checkerBoardMount}" ä¸å—æ”¯æŒ'
            logging.error(f"âŒ {error_msg}")
            raise Exception(f'checkerBoard placement value "{checkerBoardMount}" in sessionMetadata.yaml is not currently supported')

        # æ€»ç»“æ—‹è½¬è®¾ç½®
        logging.info("=" * 80)
        logging.info("ğŸ“ åæ ‡ç³»è½¬æ¢è®¾ç½®å®Œæˆ:")
        logging.info(f"   ğŸ¯ æ£‹ç›˜æ ¼æ”¾ç½®: {checkerBoardMount}")
        if checkerBoardMount in ['backWall', 'Perpendicular']:
            logging.info(f"   ğŸ§­ å€’ç½®æ£€æµ‹: {upsideDownChecker}")
        logging.info(f"   ğŸ”„ æœ€ç»ˆæ—‹è½¬è§’åº¦: {rotationAngles}")
        logging.info("   ğŸ“š åæ ‡ç³»è¯´æ˜:")
        logging.info("      - è¿åŠ¨æ•è·åæ ‡ç³»: åŸºäºæ£‹ç›˜æ ¼å»ºç«‹çš„åŸå§‹åæ ‡ç³»")
        logging.info("      - OpenSimåæ ‡ç³»: Yè½´å‘ä¸Š((positive YæŒ‡å‘å‚ç›´å‘ä¸Šï¼Œé‡åŠ›æ–¹å‘ä¸ºè´ŸYï¼‰ï¼ŒXè½´å‘å‰(positive YæŒ‡å‘å‚ç›´å‘ä¸Šï¼Œé‡åŠ›æ–¹å‘ä¸ºè´ŸYï¼‰)ï¼ŒZè½´å‘å³(positive ZæŒ‡å‘å—è¯•è€…çš„å³ä¾§)")
        logging.info("      - è¿™äº›è§’åº¦å°†ç”¨äºä»è¿åŠ¨æ•è·åæ ‡ç³»è½¬æ¢åˆ°OpenSimåæ ‡ç³»")
        logging.info("=" * 80)

        # Detect all available cameras (ie, cameras with existing videos).
        cameras_available = []
        for camName in cameraDirectories:
            camDir = cameraDirectories[camName]
            pathVideoWithoutExtension = os.path.join(camDir, 'InputMedia', trialName, trial_id)
            if len(glob.glob(pathVideoWithoutExtension + '*')) == 0:
                print(f"Camera {camName} does not have a video for trial {trial_id}")
            else:
                if os.path.exists(os.path.join(pathVideoWithoutExtension + getVideoExtension(pathVideoWithoutExtension))):
                    cameras_available.append(camName)
                else:
                    print(f"Camera {camName} does not have a video for trial {trial_id}")

        if camerasToUse[0] == 'all':
            cameras_all = list(cameraDirectories.keys())
            if not all([cam in cameras_available for cam in cameras_all]):
                exception = 'Not all cameras have uploaded videos; one or more cameras might have turned off or lost connection'
                raise Exception(exception, exception)
            else:
                camerasToUse_c = camerasToUse
        elif camerasToUse[0] == 'all_available':
            camerasToUse_c = cameras_available
            print(f"Using available cameras: {camerasToUse_c}")
        else:
            if not all([cam in cameras_available for cam in camerasToUse]):
                raise Exception('Not all specified cameras in camerasToUse have videos; verify the camera names or consider setting camerasToUse to ["all_available"]')
            else:
                camerasToUse_c = camerasToUse
                print(f"Using cameras: {camerasToUse_c}")
        settings['camerasToUse'] = camerasToUse_c
        if camerasToUse_c[0] != 'all' and len(camerasToUse_c) < 2:
            exception = 'At least two videos are required for 3D reconstruction, video upload likely failed for one or more cameras.'
            raise Exception(exception, exception)
            
        # For neutral, we do not allow reprocessing with not all cameras.
        # The reason is that it affects extrinsics selection, and then you can only process
        # dynamic trials with the same camera selection (ie, potentially not all cameras). 
        # This might be addressable, but I (Antoine) do not see an immediate need + this
        # would be a significant change in the code base. In practice, a data collection
        # will not go through neutral if not all cameras are available.
        if scaleModel:
            if camerasToUse_c[0] != 'all' and len(camerasToUse_c) < len(cameraDirectories):
                exception = 'All cameras are required for calibration and neutral pose.'
                raise Exception(exception, exception)
        
        # Run pose detection algorithm.
        try:        
            videoExtension = runPoseDetector(
                    cameraDirectories, trialRelativePath, poseDetectorDirectory,
                    trialName, CamParamDict=CamParamDict, 
                    resolutionPoseDetection=resolutionPoseDetection, 
                    generateVideo=generateVideo, cams2Use=camerasToUse_c,
                    poseDetector=poseDetector, bbox_thr=bbox_thr)
            trialRelativePath += videoExtension
        except Exception as e:
            if len(e.args) == 2: # specific exception
                raise Exception(e.args[0], e.args[1])
            elif len(e.args) == 1: # generic exception
                exception = """Pose detection failed. Verify your setup and try again. 
                    Visit https://www.opencap.ai/best-pratices to learn more about data collection
                    and https://www.opencap.ai/troubleshooting for potential causes for a failed trial."""
                raise Exception(exception, traceback.format_exc())
      
    if runSynchronization:
        # Synchronize videos.
        try:
            keypoints2D, confidence, keypointNames, frameRate, nansInOut, startEndFrames, cameras2Use = (
                synchronizeVideos( 
                    cameraDirectories, trialRelativePath, poseDetectorDirectory,
                    undistortPoints=True, CamParamDict=CamParamDict,
                    filtFreqs=filtFreqs, confidenceThreshold=0.4,
                    imageBasedTracker=False, cams2Use=camerasToUse_c, 
                    poseDetector=poseDetector, trialName=trialName,
                    resolutionPoseDetection=resolutionPoseDetection))
        except Exception as e:
            if len(e.args) == 2: # specific exception
                raise Exception(e.args[0], e.args[1])
            elif len(e.args) == 1: # generic exception
                exception = """Video synchronization failed. Verify your setup and try again. 
                    A fail-safe synchronization method is for the participant to
                    quickly raise one hand above their shoulders, then bring it back down. 
                    Visit https://www.opencap.ai/best-pratices to learn more about 
                    data collection and https://www.opencap.ai/troubleshooting for 
                    potential causes for a failed trial."""
                raise Exception(exception, traceback.format_exc())
                
    # Note: this should not be necessary, because we prevent reprocessing the neutral trial
    # with not all cameras, but keeping it in there in case we would want to.
    if calibrationOptions is not None:
        allCams = list(calibrationOptions.keys())
        for cam_t in allCams:
            if not cam_t in cameras2Use:
                calibrationOptions.pop(cam_t)
                
    if scaleModel and calibrationOptions is not None and alternateExtrinsics is None:
        logging.info("ğŸ§  æ­£åœ¨è§¦å‘è‡ªåŠ¨å¤–å‚è§£é€‰æ‹© autoSelectExtrinsicSolution ...")
        logging.info(f"   æ¡ä»¶: scaleModel={scaleModel}, has calibrationOptions={calibrationOptions is not None}, alternateExtrinsics={alternateExtrinsics}")
        # Automatically select the camera calibration to use
        CamParamDict = autoSelectExtrinsicSolution(sessionDir,keypoints2D,confidence,calibrationOptions)
        # Report the chosen solutions if the JSON file exists
        try:
            calibSelPath = os.path.join(sessionDir, 'Videos', 'calibOptionSelections.json')
            if os.path.exists(calibSelPath):
                with open(calibSelPath, 'r', encoding='utf-8') as f:
                    chosen = json.load(f)
                logging.info("âœ… è‡ªåŠ¨å¤–å‚é€‰æ‹©å®Œæˆï¼Œé€‰æ‹©ç»“æœå¦‚ä¸‹(ç›¸æœº: è§£ç´¢å¼•):")
                for cam, sol in chosen.items():
                    logging.info(f"   - {cam}: soln{sol}")
            else:
                logging.info("â„¹ï¸ æœªæ‰¾åˆ° calibOptionSelections.jsonï¼›è‡ªåŠ¨é€‰æ‹©å·²æ‰§è¡Œï¼Œä½†æœªå†™å‡ºé€‰æ‹©æ–‡ä»¶ã€‚")
        except Exception as e:
            logging.warning(f"âš ï¸ è¯»å–è‡ªåŠ¨é€‰æ‹©ç»“æœæ—¶å‡ºé”™: {str(e)}")
    else:
        logging.info("â„¹ï¸ è·³è¿‡è‡ªåŠ¨å¤–å‚è§£é€‰æ‹©ï¼š")
        logging.info(f"   æ¡ä»¶: scaleModel={scaleModel}, has calibrationOptions={calibrationOptions is not None}, alternateExtrinsics={alternateExtrinsics}")
     
    if runTriangulation:
        # Triangulate.
        logging.info("=" * 80)
        logging.info("ğŸ”º å¼€å§‹3Dä¸‰è§’åŒ–é‡å»º")
        logging.info("=" * 80)
        logging.info(f"   ğŸ“· ä½¿ç”¨æ‘„åƒå¤´: {cameras2Use}")
        logging.info(f"   ğŸï¸  å¸§ç‡: {frameRate} fps")

        # è¯¦ç»†è®°å½•æ‘„åƒå¤´å‚æ•°
        logging.info("   ğŸ“· æ‘„åƒå¤´å¤–å‚è¯¦æƒ…:")
        for cam_name in cameras2Use:
            if cam_name in CamParamDict:
                cam_params = CamParamDict[cam_name]
                if 'rotation' in cam_params:
                    import numpy as np  # ç¡®ä¿numpyåœ¨æœ¬åœ°ä½œç”¨åŸŸå†…å¯ç”¨
                    rotation = cam_params['rotation']
                    translation = cam_params['translation']
                    logging.info(f"      {cam_name}:")
                    logging.info(f"        æ—‹è½¬çŸ©é˜µ: {np.array2string(rotation.flatten()[:6], precision=3)}...")
                    logging.info(f"        å¹³ç§»å‘é‡: {np.array2string(translation.flatten(), precision=3)}")
                else:
                    logging.info(f"      {cam_name}: å¤–å‚æ ¼å¼æœªçŸ¥")

        # å®‰å…¨åœ°è·å–2Då…³é”®ç‚¹æ•°æ®ä¿¡æ¯
        try:
            if 'keypoints2D' in locals() and keypoints2D is not None:
                if hasattr(keypoints2D, 'shape'):
                    logging.info(f"   ğŸ“Š 2Då…³é”®ç‚¹æ•°æ®å½¢çŠ¶: {keypoints2D.shape}")
                elif isinstance(keypoints2D, dict):
                    logging.info(f"   ğŸ“Š 2Då…³é”®ç‚¹æ•°æ®: {len(keypoints2D)} ä¸ªæ‘„åƒå¤´")
                    for cam_name, data in keypoints2D.items():
                        if hasattr(data, 'shape'):
                            logging.info(f"      {cam_name}: {data.shape}")
                            # åˆ†æ2Då…³é”®ç‚¹çš„åˆ†å¸ƒ
                            if data.size > 0:
                                valid_points = data[~np.isnan(data)]
                                if len(valid_points) > 0:
                                    logging.info(f"        æœ‰æ•ˆç‚¹èŒƒå›´: X[{np.min(valid_points):.1f}, {np.max(valid_points):.1f}]")
                else:
                    logging.info(f"   ğŸ“Š 2Då…³é”®ç‚¹æ•°æ®ç±»å‹: {type(keypoints2D)}")
            else:
                logging.info(f"   ğŸ“Š 2Då…³é”®ç‚¹æ•°æ®: æœªåˆå§‹åŒ–")
        except Exception as e:
            logging.info(f"   ğŸ“Š 2Då…³é”®ç‚¹æ•°æ®: è·å–ä¿¡æ¯æ—¶å‡ºé”™ - {str(e)}")

        try:
            keypoints3D, confidence3D = triangulateMultiviewVideo(
                CamParamDict, keypoints2D, ignoreMissingMarkers=False,
                cams2Use=cameras2Use, confidenceDict=confidence,
                spline3dZeros = True, splineMaxFrames=int(frameRate/5),
                nansInOut=nansInOut,CameraDirectories=cameraDirectories,
                trialName=trialName,startEndFrames=startEndFrames,trialID=trial_id,
                outputMediaFolder=outputMediaFolder)

            logging.info("âœ… 3Dä¸‰è§’åŒ–é‡å»ºæˆåŠŸå®Œæˆ")
            logging.info(f"   ğŸ“ 3Då…³é”®ç‚¹æ•°æ®å½¢çŠ¶: {keypoints3D.shape}")
            logging.info(f"   ğŸ“Š ç½®ä¿¡åº¦æ•°æ®å½¢çŠ¶: {confidence3D.shape}")

            # è¯¦ç»†åˆ†æ3Dé‡å»ºç»“æœ
            logging.info("   ğŸ” 3Dé‡å»ºè´¨é‡åˆ†æ:")
            if keypoints3D.size > 0:
                # åˆ†æå„ä¸ªè½´çš„æ•°æ®åˆ†å¸ƒ
                x_data = keypoints3D[0, :, :].flatten()
                y_data = keypoints3D[1, :, :].flatten()
                z_data = keypoints3D[2, :, :].flatten()

                valid_x = x_data[~np.isnan(x_data)]
                valid_y = y_data[~np.isnan(y_data)]
                valid_z = z_data[~np.isnan(z_data)]

                if len(valid_x) > 0:
                    logging.info(f"      Xè½´èŒƒå›´: [{np.min(valid_x):.3f}, {np.max(valid_x):.3f}] mm, æ ‡å‡†å·®: {np.std(valid_x):.3f}")
                if len(valid_y) > 0:
                    logging.info(f"      Yè½´èŒƒå›´: [{np.min(valid_y):.3f}, {np.max(valid_y):.3f}] mm, æ ‡å‡†å·®: {np.std(valid_y):.3f}")
                if len(valid_z) > 0:
                    logging.info(f"      Zè½´èŒƒå›´: [{np.min(valid_z):.3f}, {np.max(valid_z):.3f}] mm, æ ‡å‡†å·®: {np.std(valid_z):.3f}")

                # å¿«é€Ÿæ¯”ä¾‹æ£€æŸ¥ï¼šZ è½´èŒƒå›´æ˜¯å¦è¿œå¤§äº X/Yï¼ˆå¯æç¤ºå¤–å‚æˆ–åæ ‡ç³»é—®é¢˜ï¼‰
                try:
                    x_span = float(np.nanmax(valid_x) - np.nanmin(valid_x)) if len(valid_x) else np.nan
                    y_span = float(np.nanmax(valid_y) - np.nanmin(valid_y)) if len(valid_y) else np.nan
                    z_span = float(np.nanmax(valid_z) - np.nanmin(valid_z)) if len(valid_z) else np.nan
                    if np.isfinite(x_span) and np.isfinite(y_span) and np.isfinite(z_span):
                        xy_span = max(x_span, y_span, 1e-6)
                        ratio = z_span / xy_span
                        if ratio > 5:
                            logging.warning(f"      âš ï¸ Zè½´èŒƒå›´({z_span:.1f})æ˜¾è‘—å¤§äºXY({xy_span:.1f}), æ¯”ä¾‹â‰ˆ{ratio:.1f}ï¼Œå¯èƒ½å­˜åœ¨å¤–å‚/åæ ‡ç³»é—®é¢˜")
                except Exception:
                    pass

                # è®¡ç®—äººä½“å°ºåº¦ç‰¹å¾
                if keypoints3D.shape[2] > 0:
                    # é€‰æ‹©ç¬¬ä¸€å¸§è¿›è¡Œåˆ†æ
                    frame_data = keypoints3D[:, :, 0]
                    valid_frame = frame_data[:, ~np.isnan(frame_data).any(axis=0)]

                    if valid_frame.shape[1] > 1:
                        # è®¡ç®—ç‚¹ä¹‹é—´çš„è·ç¦»åˆ†å¸ƒ
                        distances = []
                        for i in range(valid_frame.shape[1]):
                            for j in range(i+1, valid_frame.shape[1]):
                                dist = np.linalg.norm(valid_frame[:, i] - valid_frame[:, j])
                                distances.append(dist)

                        if distances:
                            logging.info(f"      ç‚¹é—´è·ç¦»: å¹³å‡ {np.mean(distances):.3f}mm, æœ€å¤§ {np.max(distances):.3f}mm")

                            # åˆ¤æ–­å°ºåº¦æ˜¯å¦åˆç†ï¼ˆäººä½“é«˜åº¦å¤§æ¦‚1000-2000mmï¼‰
                            max_dist = np.max(distances)
                            if max_dist < 500:
                                logging.warning(f"      âš ï¸ äººä½“å°ºåº¦å¯èƒ½è¿‡å°ï¼Œæœ€å¤§è·ç¦»ä»… {max_dist:.3f}mm")
                            elif max_dist > 5000:
                                logging.warning(f"      âš ï¸ äººä½“å°ºåº¦å¯èƒ½è¿‡å¤§ï¼Œæœ€å¤§è·ç¦»è¾¾ {max_dist:.3f}mm")
                            else:
                                logging.info(f"      âœ… äººä½“å°ºåº¦çœ‹èµ·æ¥åˆç†")

        except Exception as e:
            logging.error("âŒ 3Dä¸‰è§’åŒ–é‡å»ºå¤±è´¥")
            if len(e.args) == 2: # specific exception
                logging.error(f"   å…·ä½“é”™è¯¯: {e.args[0]}")
                logging.error(e.args[0], exc_info=True)
                raise Exception(e.args[0], e.args[1])
            elif len(e.args) == 1: # generic exception
                exception = "Triangulation failed. Verify your setup and try again. Visit https://www.opencap.ai/best-pratices to learn more about data collection and https://www.opencap.ai/troubleshooting for potential causes for a failed trial."
                logging.error(f"   é€šç”¨é”™è¯¯: {exception}")
                logging.error(exception, exc_info=True)
                raise Exception(exception, traceback.format_exc())

        # Throw an error if not enough data
        valid_frames = keypoints3D.shape[2]
        logging.info(f"   âœ… æœ‰æ•ˆ3Dæ•°æ®å¸§æ•°: {valid_frames}")

        if valid_frames < 10:
            error_msg = f'é”™è¯¯ - æœ‰æ•ˆçš„3Dæ•°æ®å¸§æ•°å°‘äº10å¸§ (å½“å‰: {valid_frames}å¸§)'
            logging.error(f"âŒ {error_msg}")
            logging.error("   å¯èƒ½åŸå› :")
            logging.error("   - 2Då§¿æ€æ£€æµ‹è´¨é‡å·®")
            logging.error("   - æ‘„åƒå¤´æ ‡å®šä¸å‡†ç¡®")
            logging.error("   - è§†é¢‘åŒæ­¥å¤±è´¥")
            logging.error("   - è¢«è¯•äººå‘˜åœ¨æ‘„åƒå¤´è§†é‡èŒƒå›´å¤–")
            raise Exception(error_msg, error_msg)

        # Write TRC.
        logging.info("=" * 80)
        logging.info("ğŸ“ å¼€å§‹å†™å…¥TRCæ–‡ä»¶")
        logging.info("=" * 80)
        logging.info(f"   ğŸ“ è¾“å‡ºæ–‡ä»¶: {pathOutputFiles[trialName]}")
        logging.info(f"   ğŸ·ï¸  å…³é”®ç‚¹åç§°æ•°é‡: {len(keypointNames)}")
        logging.info(f"   ğŸ”„ åº”ç”¨çš„æ—‹è½¬è§’åº¦: {rotationAngles}")
        logging.info(f"   ğŸï¸  å¸§ç‡: {frameRate} fps")

        # è®°å½•3Dæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
        import numpy as np
        logging.info("   ğŸ“Š 3Dæ•°æ®ç»Ÿè®¡:")
        logging.info(f"      æ•°æ®å½¢çŠ¶: {keypoints3D.shape}")
        logging.info(f"      æœ€å°å€¼: {np.nanmin(keypoints3D):.3f}")
        logging.info(f"      æœ€å¤§å€¼: {np.nanmax(keypoints3D):.3f}")
        logging.info(f"      å¹³å‡å€¼: {np.nanmean(keypoints3D):.3f}")
        logging.info(f"      NaNæ¯”ä¾‹: {np.isnan(keypoints3D).sum() / keypoints3D.size * 100:.1f}%")

        # åˆ†æåæ ‡ç³»è½¬æ¢å‰çš„æ•°æ®ç‰¹å¾
        logging.info("   ğŸ”„ åæ ‡ç³»è½¬æ¢å‰æ•°æ®åˆ†æ:")
        if keypoints3D.shape[2] > 0:
            first_frame = keypoints3D[:, :, 0]
            valid_points = first_frame[:, ~np.isnan(first_frame).any(axis=0)]

            if valid_points.shape[1] > 0:
                logging.info(f"      è½¬æ¢å‰åæ ‡ç³»ç‰¹å¾:")
                logging.info(f"        Xè½´ (è½¬æ¢å‰): [{np.min(valid_points[0, :]):.1f}, {np.max(valid_points[0, :]):.1f}] mm")
                logging.info(f"        Yè½´ (è½¬æ¢å‰): [{np.min(valid_points[1, :]):.1f}, {np.max(valid_points[1, :]):.1f}] mm")
                logging.info(f"        Zè½´ (è½¬æ¢å‰): [{np.min(valid_points[2, :]):.1f}, {np.max(valid_points[2, :]):.1f}] mm")

                # è®¡ç®—é‡å¿ƒä½ç½®
                centroid = np.mean(valid_points, axis=1)
                logging.info(f"        é‡å¿ƒä½ç½®: [{centroid[0]:.1f}, {centroid[1]:.1f}, {centroid[2]:.1f}] mm")

                # åˆ†æåæ ‡ç³»æ–¹å‘æ€§
                y_spread = np.max(valid_points[1, :]) - np.min(valid_points[1, :])
                x_spread = np.max(valid_points[0, :]) - np.min(valid_points[0, :])
                z_spread = np.max(valid_points[2, :]) - np.min(valid_points[2, :])
                logging.info(f"        å„è½´åˆ†å¸ƒèŒƒå›´: X={x_spread:.1f}, Y={y_spread:.1f}, Z={z_spread:.1f} mm")

                # æ¨æ–­å¯èƒ½çš„åæ ‡ç³»é—®é¢˜
                if abs(centroid[1]) > 1000:  # Yè½´é‡å¿ƒåç¦»è¿‡å¤§
                    logging.warning(f"      âš ï¸ Yè½´é‡å¿ƒä½ç½®å¼‚å¸¸: {centroid[1]:.1f}mmï¼Œå¯èƒ½å­˜åœ¨åæ ‡ç³»è½¬æ¢é—®é¢˜")

                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ–¹å‘æ€§é”™è¯¯
                if y_spread < x_spread and y_spread < z_spread:
                    logging.warning(f"      âš ï¸ Yè½´åˆ†å¸ƒèŒƒå›´æœ€å°ï¼Œå¯èƒ½ä¸æ˜¯å‚ç›´è½´ï¼Œæ£€æŸ¥åæ ‡ç³»è®¾ç½®")

        writeTRCfrom3DKeypoints(keypoints3D, pathOutputFiles[trialName],
                                keypointNames, frameRate=frameRate,
                                rotationAngles=rotationAngles)

        # é¢å¤–å¯¼å‡ºè°ƒè¯•ç”¨3Dé‡‡æ ·JSONï¼Œä¾¿äºå¿«é€Ÿäººå·¥æ£€æŸ¥
        try:
            from utilsChecker import save3DPointsDebug
            debug_dir = os.path.join(preAugmentationDir, 'Debug3D')
            os.makedirs(debug_dir, exist_ok=True)
            debug_json_path = os.path.join(debug_dir, f"{trial_id}_3d_sample.json")
            save3DPointsDebug(keypoints3D, keypointNames, frameRate, debug_json_path,
                              sample_strategy='auto', max_frames=10, rotationAngles=rotationAngles)
            logging.info(f"   ğŸ§ª å·²å¯¼å‡º3Dè°ƒè¯•JSON: {debug_json_path}")
        except Exception as e:
            logging.warning(f"   âš ï¸ å¯¼å‡º3Dè°ƒè¯•JSONå¤±è´¥: {str(e)}")

        logging.info("âœ… TRCæ–‡ä»¶å†™å…¥å®Œæˆ")
        logging.info("   ğŸ“ è¯´æ˜: TRCæ–‡ä»¶åŒ…å«äº†ç»è¿‡åæ ‡ç³»è½¬æ¢çš„3Dæ ‡è®°ç‚¹æ•°æ®")
        logging.info("   ğŸ”„ åæ ‡ç³»: å·²ä»è¿åŠ¨æ•è·åæ ‡ç³»è½¬æ¢ä¸ºOpenSimåæ ‡ç³»")
        logging.info("=" * 80)
    
    # %% Augmentation.
    
    # Get augmenter model.
    augmenterModelName = (
        sessionMetadata['markerAugmentationSettings']['markerAugmenterModel'])
    
    # Set output file name.
    pathAugmentedOutputFiles = {}
    if genericFolderNames:
        pathAugmentedOutputFiles[trialName] = os.path.join(
                postAugmentationDir, trial_id + ".trc")
    else:
        if benchmark:
            pathAugmentedOutputFiles[trialName] = os.path.join(
                    postAugmentationDir, trialName + "_" + augmenterModelName +".trc")
        else:
            pathAugmentedOutputFiles[trialName] = os.path.join(
                    postAugmentationDir, trial_id + "_" + augmenterModelName +".trc")
    
    if runMarkerAugmentation:
        os.makedirs(postAugmentationDir, exist_ok=True)    
        augmenterDir = os.path.join(baseDir, "MarkerAugmenter")
        logging.info('Augmenting marker set')
        try:
            vertical_offset = augmentTRC(
                pathOutputFiles[trialName],sessionMetadata['mass_kg'], 
                sessionMetadata['height_m'], pathAugmentedOutputFiles[trialName],
                augmenterDir, augmenterModelName=augmenterModelName,
                augmenter_model=augmenterModel, offset=offset)
        except Exception as e:
            if len(e.args) == 2: # specific exception
                raise Exception(e.args[0], e.args[1])
            elif len(e.args) == 1: # generic exception
                exception = "Marker augmentation failed. Verify your setup and try again. Visit https://www.opencap.ai/best-pratices to learn more about data collection and https://www.opencap.ai/troubleshooting for potential causes for a failed trial."
                raise Exception(exception, traceback.format_exc())
        if offset:
            # If offset, no need to offset again for the webapp visualization.
            # (0.01 so that there is no overall offset, see utilsOpenSim).
            vertical_offset_settings = float(np.copy(vertical_offset)-0.01)
            vertical_offset = 0.01   
        
    # %% OpenSim pipeline.
    if runOpenSimPipeline:
        logging.info("=" * 80)
        logging.info("ğŸ¦´ å¼€å§‹OpenSimç”Ÿç‰©åŠ›å­¦åˆ†æç®¡é“")
        logging.info("=" * 80)

        openSimPipelineDir = os.path.join(baseDir, "opensimPipeline")

        if genericFolderNames:
            openSimFolderName = 'OpenSimData'
        else:
            openSimFolderName = os.path.join('OpenSimData',
                                             poseDetector + suff_pd)
            if not markerDataFolderNameSuffix is None:
                openSimFolderName = os.path.join(openSimFolderName,
                                                 markerDataFolderNameSuffix)

        openSimDir = os.path.join(sessionDir, openSimFolderName)
        outputScaledModelDir = os.path.join(openSimDir, 'Model')

        # Check if shoulder model.
        if 'shoulder' in sessionMetadata['openSimModel']:
            suffix_model = '_shoulder'
        else:
            suffix_model = ''

        logging.info(f"   ğŸ“ OpenSimç›®å½•: {openSimDir}")
        logging.info(f"   ğŸ—ï¸  åŸºç¡€æ¨¡å‹: {sessionMetadata['openSimModel']}{suffix_model}")
        logging.info(f"   ğŸ‘¤ å—è¯•è€…ä¿¡æ¯: ä½“é‡{sessionMetadata['mass_kg']}kg, èº«é«˜{sessionMetadata['height_m']}m")
        logging.info(f"   ğŸ”§ æ˜¯å¦ç¼©æ”¾æ¨¡å‹: {scaleModel}")

        # Scaling.
        if scaleModel:
            logging.info("=" * 60)
            logging.info("ğŸ“ å¼€å§‹æ¨¡å‹ç¼©æ”¾ï¼ˆé™æ€è¯•éªŒï¼‰")
            logging.info("=" * 60)

            os.makedirs(outputScaledModelDir, exist_ok=True)
            # Path setup file.
            if scalingSetup == 'any_pose':
                genericSetupFile4ScalingName = 'Setup_scaling_LaiUhlrich2022_any_pose.xml'
                logging.info("   ğŸ§˜ ä½¿ç”¨ä»»æ„å§¿æ€ç¼©æ”¾è®¾ç½®")
            else: # by default, use upright_standing_pose
                genericSetupFile4ScalingName = 'Setup_scaling_LaiUhlrich2022.xml'
                logging.info("   ğŸ§ ä½¿ç”¨ç›´ç«‹ç«™å§¿ç¼©æ”¾è®¾ç½®")

            pathGenericSetupFile4Scaling = os.path.join(
                openSimPipelineDir, 'Scaling', genericSetupFile4ScalingName)
            # Path model file.
            pathGenericModel4Scaling = os.path.join(
                openSimPipelineDir, 'Models',
                sessionMetadata['openSimModel'] + '.osim')
            # Path TRC file.
            pathTRCFile4Scaling = pathAugmentedOutputFiles[trialName]

            logging.info(f"   ğŸ“‹ ç¼©æ”¾è®¾ç½®æ–‡ä»¶: {genericSetupFile4ScalingName}")
            logging.info(f"   ğŸ—ï¸  é€šç”¨æ¨¡å‹æ–‡ä»¶: {os.path.basename(pathGenericModel4Scaling)}")
            logging.info(f"   ğŸ“Š TRCæ•°æ®æ–‡ä»¶: {os.path.basename(pathTRCFile4Scaling)}")

            # Get time range.
            try:
                logging.info("   ğŸ¯ å¼€å§‹è¯†åˆ«ç¼©æ”¾æ—¶é—´èŒƒå›´...")
                thresholdPosition = 0.003
                maxThreshold = 0.015
                increment = 0.001
                success = False
                timeRange4Scaling = None  # åˆå§‹åŒ–å˜é‡
                attempt_count = 0

                while thresholdPosition <= maxThreshold and not success:
                    attempt_count += 1
                    try:
                        logging.info(f"      å°è¯• #{attempt_count}: ä½ç½®é˜ˆå€¼ = {thresholdPosition:.3f}")
                        timeRange4Scaling = getScaleTimeRange(
                            pathTRCFile4Scaling,
                            thresholdPosition=thresholdPosition,
                            thresholdTime=0.1, removeRoot=True)
                        success = True
                        logging.info(f"   âœ… æˆåŠŸè¯†åˆ«ç¼©æ”¾æ—¶é—´èŒƒå›´: {timeRange4Scaling}")
                    except Exception as e:
                        logging.info(f"      âŒ å¤±è´¥: {str(e)}")
                        thresholdPosition += increment  # Increase the threshold for the next iteration

                # æ£€æŸ¥æ˜¯å¦æˆåŠŸæ‰¾åˆ°æ—¶é—´èŒƒå›´
                if not success or timeRange4Scaling is None:
                    error_msg = f"æ— æ³•åœ¨å°è¯•{attempt_count}æ¬¡åæ‰¾åˆ°åˆé€‚çš„ç¼©æ”¾æ—¶é—´èŒƒå›´"
                    logging.error(f"   âŒ {error_msg}")
                    logging.error("   å¯èƒ½åŸå› :")
                    logging.error("      - é™æ€å§¿æ€æ•°æ®è´¨é‡å·®")
                    logging.error("      - å—è¯•è€…åœ¨é™æ€è¯•éªŒä¸­ç§»åŠ¨å¤ªå¤š")
                    logging.error("      - TRCæ–‡ä»¶ä¸­ç¼ºå°‘è¶³å¤Ÿçš„ç¨³å®šæ•°æ®")
                    raise Exception(error_msg)

                # Run scale tool.
                logging.info("   ğŸš€ å¼€å§‹è¿è¡Œæ¨¡å‹ç¼©æ”¾å·¥å…·...")
                logging.info(f"      æ—¶é—´èŒƒå›´: {timeRange4Scaling[0]:.3f}s - {timeRange4Scaling[1]:.3f}s")
                logging.info(f"      æŒç»­æ—¶é—´: {timeRange4Scaling[1] - timeRange4Scaling[0]:.3f}s")

                pathScaledModel = runScaleTool(
                    pathGenericSetupFile4Scaling, pathGenericModel4Scaling,
                    sessionMetadata['mass_kg'], pathTRCFile4Scaling,
                    timeRange4Scaling, outputScaledModelDir,
                    subjectHeight=sessionMetadata['height_m'],
                    suffix_model=suffix_model)

                logging.info(f"   âœ… æ¨¡å‹ç¼©æ”¾æˆåŠŸå®Œæˆ")
                logging.info(f"      ç¼©æ”¾åæ¨¡å‹: {os.path.basename(pathScaledModel)}")

            except Exception as e:
                logging.error("âŒ æ¨¡å‹ç¼©æ”¾å¤±è´¥")
                if len(e.args) == 2: # specific exception
                    logging.error(f"   å…·ä½“é”™è¯¯: {e.args[0]}")
                    raise Exception(e.args[0], e.args[1])
                elif len(e.args) == 1: # generic exception
                    exception = "Musculoskeletal model scaling failed. Verify your setup and try again. Visit https://www.opencap.ai/best-pratices to learn more about data collection and https://www.opencap.ai/troubleshooting for potential causes for a failed neutral pose."
                    logging.error(f"   é€šç”¨é”™è¯¯: {exception}")
                    raise Exception(exception, traceback.format_exc())

            # Extract one frame from videos to verify neutral pose.
            logging.info("   ğŸ“¸ æå–é™æ€å§¿æ€å›¾åƒç”¨äºéªŒè¯...")
            staticImagesFolderDir = os.path.join(sessionDir,
                                                 'NeutralPoseImages')
            os.makedirs(staticImagesFolderDir, exist_ok=True)
            popNeutralPoseImages(cameraDirectories, cameras2Use,
                                 timeRange4Scaling[0], staticImagesFolderDir,
                                 trial_id, writeVideo = True)
            logging.info(f"      éªŒè¯å›¾åƒä¿å­˜åˆ°: {staticImagesFolderDir}")

            pathOutputIK = pathScaledModel[:-5] + '.mot'
            pathModelIK = pathScaledModel

            logging.info("   ğŸ“ æ³¨æ„: ç¼©æ”¾åçš„æ¨¡å‹å°†ç”¨äºåç»­çš„é€†è¿åŠ¨å­¦åˆ†æ")

        # Inverse kinematics.
        if not scaleModel:
            logging.info("=" * 60)
            logging.info("ğŸƒ å¼€å§‹é€†è¿åŠ¨å­¦åˆ†æï¼ˆåŠ¨æ€è¯•éªŒï¼‰")
            logging.info("=" * 60)

            outputIKDir = os.path.join(openSimDir, 'Kinematics')
            os.makedirs(outputIKDir, exist_ok=True)
            # Check if there is a scaled model.
            pathScaledModel = os.path.join(outputScaledModelDir,
                                            sessionMetadata['openSimModel'] +
                                            "_scaled.osim")

            logging.info(f"   ğŸ“‚ IKè¾“å‡ºç›®å½•: {outputIKDir}")
            logging.info(f"   ğŸ” æŸ¥æ‰¾ç¼©æ”¾åæ¨¡å‹: {os.path.basename(pathScaledModel)}")

            if os.path.exists(pathScaledModel):
                logging.info("   âœ… æ‰¾åˆ°ç¼©æ”¾åçš„æ¨¡å‹")

                # Path setup file.
                genericSetupFile4IKName = 'Setup_IK{}.xml'.format(suffix_model)
                pathGenericSetupFile4IK = os.path.join(
                    openSimPipelineDir, 'IK', genericSetupFile4IKName)
                # Path TRC file.
                pathTRCFile4IK = pathAugmentedOutputFiles[trialName]

                logging.info(f"   ğŸ“‹ IKè®¾ç½®æ–‡ä»¶: {genericSetupFile4IKName}")
                logging.info(f"   ğŸ“Š TRCæ•°æ®æ–‡ä»¶: {os.path.basename(pathTRCFile4IK)}")

                # Run IK tool.
                logging.info('   ğŸš€ å¼€å§‹è¿è¡Œé€†è¿åŠ¨å­¦å·¥å…·...')
                try:
                    pathOutputIK, pathModelIK = runIKTool(
                        pathGenericSetupFile4IK, pathScaledModel,
                        pathTRCFile4IK, outputIKDir)

                    logging.info("   âœ… é€†è¿åŠ¨å­¦åˆ†ææˆåŠŸå®Œæˆ")
                    logging.info(f"      è¾“å‡ºMOTæ–‡ä»¶: {os.path.basename(pathOutputIK)}")
                    logging.info("      ğŸ“ è¯´æ˜: MOTæ–‡ä»¶åŒ…å«å…³èŠ‚è§’åº¦éšæ—¶é—´çš„å˜åŒ–")

                except Exception as e:
                    logging.error("âŒ é€†è¿åŠ¨å­¦åˆ†æå¤±è´¥")
                    if len(e.args) == 2: # specific exception
                        logging.error(f"   å…·ä½“é”™è¯¯: {e.args[0]}")
                        raise Exception(e.args[0], e.args[1])
                    elif len(e.args) == 1: # generic exception
                        exception = "Inverse kinematics failed. Verify your setup and try again. Visit https://www.opencap.ai/best-pratices to learn more about data collection and https://www.opencap.ai/troubleshooting for potential causes for a failed trial."
                        logging.error(f"   é€šç”¨é”™è¯¯: {exception}")
                        raise Exception(exception, traceback.format_exc())
            else:
                error_msg = "æœªæ‰¾åˆ°ç¼©æ”¾åçš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œé™æ€è¯•éªŒè¿›è¡Œæ¨¡å‹ç¼©æ”¾"
                logging.error(f"   âŒ {error_msg}")
                logging.error(f"   æœŸæœ›è·¯å¾„: {pathScaledModel}")
                raise ValueError(error_msg)

        # Write body transforms to json for visualization.
        logging.info("=" * 60)
        logging.info("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–æ•°æ®")
        logging.info("=" * 60)

        outputJsonVisDir = os.path.join(sessionDir,'VisualizerJsons',
                                        trialName)
        os.makedirs(outputJsonVisDir,exist_ok=True)
        outputJsonVisPath = os.path.join(outputJsonVisDir,
                                         trialName + '.json')

        logging.info(f"   ğŸ“ å¯è§†åŒ–ç›®å½•: {outputJsonVisDir}")
        logging.info(f"   ğŸ“„ JSONæ–‡ä»¶: {os.path.basename(outputJsonVisPath)}")
        logging.info(f"   ğŸ“ å‚ç›´åç§»: {vertical_offset}")

        generateVisualizerJson(pathModelIK, pathOutputIK,
                               outputJsonVisPath,
                               vertical_offset=vertical_offset,
                               roundToRotations=4, roundToTranslations=4)

        logging.info("   âœ… å¯è§†åŒ–æ•°æ®ç”Ÿæˆå®Œæˆ")
        logging.info("=" * 80)
        logging.info("ğŸ‰ OpenSimç”Ÿç‰©åŠ›å­¦åˆ†æç®¡é“å®Œæˆ")
        logging.info("=" * 80)
        
    # %% Rewrite settings, adding offset  
    if not extrinsicsTrial:
        if offset:
            settings['verticalOffset'] = vertical_offset_settings 
        with open(pathSettings, 'w', encoding='utf-8') as file:
            yaml.dump(settings, file)
    
    # è¿”å›æˆåŠŸçŠ¶æ€
    return True
